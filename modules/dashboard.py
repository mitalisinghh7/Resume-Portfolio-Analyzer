import streamlit as st
from resume_parser import extract_text_from_pdf, extract_text_from_docx
from keyword_analysis import analyze_keywords
from feedback import generate_feedback
from ats_score import calculate_ats_score
from ui_helpers import (display_resume_preview, display_keyword_analysis, display_feedback, show_summary, load_job_roles, select_job_role, display_portfolio_feedback, show_wordcloud)
from report_generator import generate_pdf_report
from portfolio_analyzer import analyze_github_profile
from storage_manager import (init_db, save_analysis, get_user_history, get_leaderboard, recalc_all_points)
from nlp_analysis import extract_keywords, generate_wordcloud_bytes, get_top_skills, get_skill_frequencies, calculate_skill_match_percentage
import pandas as pd
import matplotlib.pyplot as plt
import sqlite3
from datetime import datetime

init_db()
try:
    recalc_all_points()
except Exception:
    pass

st.set_page_config(page_title="Resume & Portfolio Analyzer", layout="wide")
st.title("üéì Resume & Portfolio Analyzer")
st.write("Welcome! Upload your resume to get started.")

for k in ["resume_text", "role", "result", "feedback", "ats_score", "last_saved_profile", "portfolio_data"]:
    if k not in st.session_state:
        st.session_state[k] = None

# layout of tabs
tab_resume, tab_portfolio, tab_progress, tab_leaderboard = st.tabs(
    ["üìÑ Resume", "üåê Portfolio", "üìà Progress", "üèÜ Leaderboard"]
)

# resume uploader & analysis
with tab_resume:
    st.header("üìÑ Resume Analyzer")
    uploaded_file = st.file_uploader("Upload Resume", type=["pdf", "docx"])
    resume_text = ""

    if uploaded_file is not None:
        file_type = uploaded_file.name.split(".")[-1].lower()
        if file_type == "pdf":
            resume_text = extract_text_from_pdf(uploaded_file)
        elif file_type == "docx":
            resume_text = extract_text_from_docx(uploaded_file)
        else:
            st.error("Unsupported file type!")

        if resume_text:
            st.session_state["resume_text"] = resume_text
            display_resume_preview(resume_text)

            job_roles = load_job_roles()
            if job_roles:
                role, keywords = select_job_role(job_roles)
                st.session_state["role"] = role
                st.write(f"üìå Selected Role: **{role}**")

                # keyword analysis
                result = analyze_keywords(resume_text, keywords)
                st.session_state["result"] = result
                display_keyword_analysis(result)

                found = result.get("found", [])
                missing = result.get("missing", [])
                feedback = generate_feedback(found, missing)
                st.session_state["feedback"] = feedback
                display_feedback(feedback)

                show_summary(result)

                # ats score
                try:
                    ats_score = calculate_ats_score(resume_text, role)
                    st.session_state["ats_score"] = ats_score
                    st.subheader("üìä ATS Score")
                    st.progress(int(ats_score))
                    st.write(f"‚≠ê Your resume scored **{ats_score}/100** for the role: **{role}**")
                except Exception as e:
                    st.error(f"Could not compute ATS score: {e}")

                # nlp insights
                st.markdown("---")
                st.subheader("üß† NLP Insights")
                try:
                    top_keywords = extract_keywords(resume_text, top_n=40)
                    if top_keywords:
                        st.write("**Top keywords (by frequency):**", ", ".join(top_keywords[:20]))
                    else:
                        st.info("No prominent keywords found.")
                except Exception as e:
                    st.warning(f"Keyword extraction failed: {e}")

                # wordcloud
                wc_bytes = None
                try:
                    wc_bytes = generate_wordcloud_bytes(resume_text)
                except Exception:
                    wc_bytes = None

                if wc_bytes:
                    show_wordcloud(wc_bytes, title="üå•Ô∏è Resume WordCloud")
                else:
                    st.info("WordCloud unavailable (install 'wordcloud' package to enable).")

                # top 5 skills
                st.markdown("---")
                st.subheader("üìä Top 5 Most Frequent Skills")
                try:
                    top_skills = get_top_skills(resume_text, top_n=5)
                    if top_skills:
                        st.write(", ".join([s.capitalize() for s in top_skills]))
                    else:
                        st.info("No top skills found.")
                except Exception as e:
                    st.warning(f"Top skills extraction failed: {e}")

                # skill frequency table and chart
                st.markdown("---")
                st.subheader("üí™ Skill Frequency Strength")
                try:
                    skill_df = get_skill_frequencies(resume_text)
                    if not skill_df.empty:
                        st.dataframe(skill_df)
                        fig, ax = plt.subplots(figsize=(6, 4))
                        ax.barh(skill_df["Skill"], skill_df["Count"])
                        ax.invert_yaxis()
                        ax.set_xlabel("Frequency")
                        ax.set_ylabel("Skill")
                        ax.set_title("Skill Strength in Resume")
                        st.pyplot(fig)
                    else:
                        st.info("No technical skills detected for frequency analysis.")
                except Exception as e:
                    st.warning(f"Skill frequency analysis failed: {e}")

                # skill match %
                st.markdown("---")
                st.subheader("üîó Skill Match Percentage")
                try:
                    percent, matched_count, total_required, matched_list = calculate_skill_match_percentage(resume_text, keywords)
                    st.metric(label="Match (%)", value=f"{percent}%")
                    st.progress(int(percent))
                    st.write(f"Matched {matched_count} out of {total_required} required keywords for **{role}**.")
                    if matched_list:
                        st.write("Matched keywords:", ", ".join(matched_list))
                    else:
                        st.info("No required keywords were matched in the resume.")

                    # combined insights
                    from ui_helpers import display_resume_insights
                    from nlp_analysis import calculate_skill_coverage

                    display_resume_insights(
                        match_percent=percent,
                        ats_score=st.session_state.get("ats_score", 0),
                        role=role,
                        missing_keywords=result.get("missing", [])
                    )

                    st.markdown("### üìã Skill Coverage Summary")
                    found_count, missing_count, coverage = calculate_skill_coverage(resume_text, keywords)
                    st.write(f"- ‚úÖ Found Skills: {found_count}")
                    st.write(f"- ‚ùå Missing Skills: {missing_count}")
                    st.write(f"- üìä Coverage: {coverage}%")

                except Exception as e:
                    st.warning(f"Could not compute skill match or insights: {e}")

# portfolio analyzer
with tab_portfolio:
    st.header("üåê Portfolio Analyzer")
    st.write("Enter your GitHub username to analyze your public portfolio.")
    username = st.text_input("GitHub Username", placeholder="e.g., torvalds")

    col_r1, col_r2, col_r3, col_r4 = st.columns(4)
    with col_r1:
        uploaded_flag = "Yes" if st.session_state.get("resume_text") else "No"
        st.metric("Resume Uploaded", uploaded_flag)
    with col_r2:
        st.metric("Selected Role", st.session_state.get("role", "N/A"))
    with col_r3:
        st.metric("Last ATS Score", st.session_state.get("ats_score", 0))
    with col_r4:
        st.metric("Alignment (%)", "N/A")

    if username:
        with st.spinner("Fetching GitHub data..."):
            data = analyze_github_profile(username)

        if "error" in data:
            st.error(data["error"])
        else:
            st.success(f"‚úÖ GitHub data fetched for **{data['username']}**")
            st.session_state["portfolio_data"] = data

            # small stats row
            subcol1, subcol2, subcol3 = st.columns(3)
            subcol1.metric("üß∞ Repositories", data["repositories"])
            subcol2.metric("üë• Followers", data["followers"])
            subcol3.metric("üî• Contributions", data["contributions"])

            display_portfolio_feedback(data.get("feedback", data.get("feedback_text", [])))

            # resume ‚Üî gitHub skill alignment
            st.markdown("---")
            st.subheader("ü§ù Resume ‚Üî GitHub Skill Alignment")

            try:
                resume_text = st.session_state.get("resume_text", "")
                github_langs = data.get("top_languages", {})

                if resume_text and github_langs:
                    langs_in_github = [lang.lower() for lang in github_langs.keys()]

                    resume_keywords = extract_keywords(resume_text, top_n=50)
                    resume_keywords = [k.lower() for k in resume_keywords]

                    matched = [lang for lang in langs_in_github if lang in resume_keywords]
                    missing = [lang for lang in langs_in_github if lang not in resume_keywords]

                    align_percent = int((len(matched) / len(langs_in_github)) * 100) if langs_in_github else 0

                    col_r4.metric("Alignment (%)", f"{align_percent}%")

                    st.metric(label="Alignment (%)", value=f"{align_percent}%")
                    st.write(f"‚úÖ **Matched Skills:** {', '.join(matched) if matched else 'None'}")
                    st.write(f"‚ùå **Missing from Resume:** {', '.join(missing) if missing else 'None'}")

                    st.markdown("#### üíª Top GitHub Languages")
                    for lang, count in github_langs.items():
                        st.write(f"- {lang}: {count:,} lines of code")

                    # combined resume & portfolio visualization
                    st.markdown("---")
                    st.subheader("üìä Resume & Portfolio Combined Visualization")
                    try:
                        col1, col2 = st.columns(2)
                        # resume skill distribution (pie chart)
                        with col1:
                            st.markdown("#### Resume Skill Distribution")
                            from nlp_analysis import get_skill_frequencies

                            resume_skill_df = get_skill_frequencies(resume_text)
                            if not resume_skill_df.empty:
                                fig1, ax1 = plt.subplots()
                                ax1.pie(
                                    resume_skill_df["Count"],
                                    labels=resume_skill_df["Skill"],
                                    autopct="%1.1f%%",
                                    startangle=90
                                )
                                ax1.axis("equal")
                                st.pyplot(fig1)
                            else:
                                st.info("No skills found in resume for visualization.")

                        # gitHub language distribution (bar chart)
                        with col2:
                            st.markdown("#### GitHub Language Distribution")
                            if github_langs:
                                fig2, ax2 = plt.subplots()
                                langs = list(github_langs.keys())
                                lines = list(github_langs.values())
                                ax2.bar(langs, lines)
                                ax2.set_xlabel("Languages")
                                ax2.set_ylabel("Lines of Code")
                                ax2.set_title("GitHub Language Distribution")
                                plt.xticks(rotation=45)
                                st.pyplot(fig2)
                            else:
                                st.info("No GitHub languages available for visualization.")

                        st.success(
                            "‚úÖ Insight: The closer the resume skill ratio matches GitHub language ratio, "
                            "the stronger your profile alignment.")

                    except Exception as e:
                        st.warning(f"Could not generate combined visualization: {e}")

                    # top github language vs resume focus
                    st.markdown("### üìä GitHub Language vs Resume Focus")
                    try:
                        top_lang = max(github_langs, key=github_langs.get)
                        resume_top_skills = get_top_skills(resume_text, top_n=1)
                        resume_focus = resume_top_skills[0] if resume_top_skills else "Unknown"

                        st.write(f"**üèÜ Top GitHub Language:** {top_lang}")
                        st.write(f"**üß† Resume Focus Area:** {resume_focus}")

                        if top_lang.lower() == resume_focus.lower():
                            st.success("Perfect alignment ‚Äî your GitHub projects reflect your resume focus! üéØ")
                        else:
                            st.info("Partial alignment ‚Äî consider adding GitHub projects related to your resume focus.")
                    except Exception as e:
                        st.warning(f"Could not analyze GitHub vs Resume focus: {e}")

                else:
                    st.info("Upload your resume and enter your GitHub username to view alignment insights.")

            except Exception as e:
                st.warning(f"Could not compute Resume ‚Üî GitHub alignment: {e}")

            already_saved = st.session_state.get("last_saved_profile")
            if already_saved != data["username"]:
                try:
                    save_analysis(
                        username=data["username"],
                        role=st.session_state.get("role", "N/A"),
                        ats_score=st.session_state.get("ats_score", 0),
                        repos=data["repositories"],
                        followers=data["followers"],
                        contributions=data["contributions"]
                    )
                    st.session_state["last_saved_profile"] = data["username"]
                except sqlite3.OperationalError as exc:
                    st.error(f"Database error while saving analysis: {exc}")
                except Exception as exc:
                    st.warning(f"‚ö†Ô∏è Could not save data: {exc}")
            else:
                st.info("Profile data already saved in this session (to avoid duplicates).")

            # export pdf
            if st.button("üìÑ Export combined PDF report"):
                with st.spinner("Generating PDF..."):
                    try:
                        from nlp_analysis import get_skill_frequencies

                        resume_skill_df = get_skill_frequencies(st.session_state.get("resume_text", ""))
                        filename = generate_pdf_report(
                            role=st.session_state.get("role", "N/A"),
                            result=st.session_state.get("result", {"found": [], "missing": []}),
                            feedback=st.session_state.get("feedback", []),
                            ats_score=st.session_state.get("ats_score", 0),
                            portfolio_data=data,
                            resume_skill_df=resume_skill_df)

                        st.success("‚úÖ PDF report generated successfully!")
                        with open(filename, "rb") as pdf_file:
                            st.download_button("‚¨áÔ∏è Download Report", data=pdf_file, file_name=filename, mime="application/pdf")
                    except Exception as e:
                        st.error(f"Could not generate PDF: {e}")

# progress history
with tab_progress:
    st.header("üìà Progress History")
    st.write("Track your ATS score history and improvements over time.")
    username_for_history = st.text_input("History: Enter GitHub username to view progress", value="")

    if username_for_history:
        try:
            history = get_user_history(username_for_history)
        except sqlite3.OperationalError as exc:
            st.error(f"Database error while fetching history: {exc}")
            history = []
        except Exception as exc:
            st.warning(f"Could not fetch history: {exc}")
            history = []

        if history:
            df = pd.DataFrame(history, columns=["Role", "ATS Score", "Repositories", "Followers", "Contributions", "Points", "Date"])
            st.dataframe(df)
            st.markdown("#### ATS Score Trend")
            try:
                df["Date"] = pd.to_datetime(df["Date"])
            except Exception:
                pass
            fig, ax = plt.subplots(figsize=(6, 4))
            ax.plot(df["Date"], df["ATS Score"], marker="o", linestyle="-", color="royalblue", linewidth=2)
            ax.set_xlabel("Date")
            ax.set_ylabel("ATS Score")
            ax.set_title("ATS Score Over Time")
            plt.xticks(rotation=45)
            ax.grid(True, linestyle="--", alpha=0.5)
            st.pyplot(fig)
        else:
            st.info("No progress history yet ‚Äî analyze a resume to start tracking your growth!")

    # clear history
    st.markdown("---")
    st.subheader("üßπ Manage Your Data")
    if st.button("Clear My History"):
        if username_for_history:
            try:
                conn = sqlite3.connect("analysis_history.db")
                c = conn.cursor()
                c.execute("DELETE FROM history WHERE username=?", (username_for_history,))
                conn.commit()
                conn.close()
                st.success("‚úÖ History cleared successfully!")
            except Exception as e:
                st.error(f"Could not clear history: {e}")
        else:
            st.warning("Enter the username above to clear that user's history.")

# leaderboard
with tab_leaderboard:
    st.header("üèÜ Leaderboard")
    try:
        leaderboard = get_leaderboard()
    except Exception as exc:
        st.error(f"Could not load leaderboard: {exc}")
        leaderboard = []
    if leaderboard:
        leaderboard_df = pd.DataFrame(leaderboard, columns=["Username", "Avg ATS Score", "Total Contributions", "Total Points"])
        leaderboard_df.index = leaderboard_df.index + 1
        st.dataframe(leaderboard_df)
    else:
        st.info("No leaderboard data yet!")